<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Enhanced Milk Overflow Detector</title>
  <style>
    body { 
      display: flex; 
      flex-direction: column; 
      align-items: center; 
      font-family: sans-serif; 
      margin: 0; 
      padding: 20px; 
      background: #f5f5f5;
    }
    
    .video-container {
      position: relative;
      width: 90%;
      max-width: 400px;
      margin-bottom: 20px;
      border: 2px solid #333;
      border-radius: 8px;
      overflow: hidden;
      background: #000;
    }
    
    video { 
      width: 100%; 
      height: auto;
      display: block;
      transform-origin: center center;
      transition: transform 0.2s ease;
    }
    
    .zoom-overlay {
      position: absolute;
      top: 10px;
      right: 10px;
      background: rgba(0,0,0,0.8);
      color: white;
      padding: 8px 12px;
      border-radius: 5px;
      font-size: 14px;
      font-weight: bold;
    }
    
    .target-zone {
      position: absolute;
      border: 3px dashed #ff4444;
      background: rgba(255, 68, 68, 0.15);
      pointer-events: none;
      display: none;
      z-index: 10;
    }
    
    .controls {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      justify-content: center;
      margin-bottom: 20px;
    }
    
    button { 
      padding: 12px 20px; 
      font-size: 14px;
      font-weight: bold;
      border: none;
      border-radius: 6px;
      cursor: pointer;
      background: #007bff;
      color: white;
      transition: all 0.3s;
      min-width: 120px;
    }
    
    button:hover { 
      background: #0056b3; 
      transform: translateY(-1px);
    }
    button:disabled { 
      background: #ccc; 
      cursor: not-allowed; 
      transform: none;
    }
    
    .zoom-controls {
      display: flex;
      gap: 10px;
      align-items: center;
      margin-bottom: 20px;
      padding: 15px;
      background: white;
      border-radius: 8px;
      box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
    
    input[type="range"] {
      width: 150px;
      height: 6px;
      background: #ddd;
      border-radius: 3px;
      outline: none;
      cursor: pointer;
    }
    
    input[type="range"]::-webkit-slider-thumb {
      appearance: none;
      width: 20px;
      height: 20px;
      background: #007bff;
      border-radius: 50%;
      cursor: pointer;
    }
    
    .status {
      padding: 15px;
      margin: 10px 0;
      border-radius: 8px;
      text-align: center;
      font-weight: bold;
      width: 90%;
      max-width: 400px;
    }
    
    .status.loading { background: #fff3cd; color: #856404; }
    .status.ready { background: #d4edda; color: #155724; }
    .status.monitoring { background: #cce5ff; color: #004085; }
    .status.alert { background: #f8d7da; color: #721c24; }
    
    .detection-info {
      background: white;
      padding: 20px;
      border-radius: 8px;
      box-shadow: 0 2px 10px rgba(0,0,0,0.1);
      margin-top: 10px;
      width: 90%;
      max-width: 400px;
    }
    
    .info-row {
      display: flex;
      justify-content: space-between;
      margin-bottom: 10px;
      padding: 5px 0;
    }
    
    .info-label {
      font-weight: bold;
      color: #333;
    }
    
    .info-value {
      color: #666;
    }
    
    .confidence-bar {
      width: 100%;
      height: 24px;
      background: #eee;
      border-radius: 12px;
      overflow: hidden;
      margin-top: 10px;
      position: relative;
    }
    
    .confidence-fill {
      height: 100%;
      background: linear-gradient(90deg, #28a745, #ffc107, #dc3545);
      border-radius: 12px;
      transition: width 0.5s ease;
      width: 0%;
    }
    
    .confidence-text {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      color: white;
      font-weight: bold;
      text-shadow: 1px 1px 2px rgba(0,0,0,0.5);
      font-size: 12px;
    }
  </style>
</head>
<body>
  <h1>ðŸ¥› Enhanced Milk Overflow Detector</h1>
  
  <div class="status loading" id="status">Initializing camera and ML model...</div>
  
  <div class="video-container">
    <video id="video" autoplay playsinline muted></video>
    <div class="zoom-overlay" id="zoomLevel">Zoom: 1.0x</div>
    <div class="target-zone" id="targetZone"></div>
  </div>
  
  <div class="zoom-controls">
    <label for="zoomSlider" style="font-weight: bold;">Zoom:</label>
    <input type="range" id="zoomSlider" min="1" max="4" step="0.2" value="1">
    <span id="zoomValue" style="font-weight: bold; min-width: 50px;">1.0x</span>
    <button id="resetZoomBtn" style="min-width: 80px; padding: 8px 15px;">Reset</button>
  </div>
  
  <div class="controls">
    <button id="startBtn" disabled>Start Monitoring</button>
    <button id="setTargetBtn">Set Target Zone</button>
  </div>
  
  <div class="detection-info">
    <div class="info-row">
      <span class="info-label">Detection Status:</span>
      <span class="info-value" id="detectionStatus">Standby</span>
    </div>
    <div class="info-row">
      <span class="info-label">Overflow Risk:</span>
      <span class="info-value" id="riskLevel">Low</span>
    </div>
    <div class="info-row">
      <span class="info-label">ML Model:</span>
      <span class="info-value" id="modelStatus">Loading...</span>
    </div>
    <div style="margin-top: 15px;">
      <div class="info-label" style="margin-bottom: 5px;">Risk Confidence:</div>
      <div class="confidence-bar">
        <div class="confidence-fill" id="confidenceFill"></div>
        <div class="confidence-text" id="confidenceText">0%</div>
      </div>
    </div>
  </div>

  <audio id="alarm" preload="auto">
    <source src="data:audio/wav;base64,UklGRnoGAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQoGAACBhYqFbF1fdJivrJBhNjVgodDbq2EcBj+a2/LDciUFLIHO8tiJNwgZaLvt559NEAxQp+PwtmMcBjiR1/LMeSwFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFApGn+DyvmMcBT2O2fPNeSsFJHfH8N2QQAoUXrTp66hVFA==" type="audio/wav">
  </audio>

  <!-- Load TensorFlow.js -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.10.0/tf.min.js"></script>

  <script>
    // Global variables
    let video, model, monitoring = false;
    let zoomLevel = 1.0;
    let targetZone = null;
    let isSettingTarget = false;
    let modelLoaded = false;
    
    // UI elements
    const statusEl = document.getElementById('status');
    const startBtn = document.getElementById('startBtn');
    const setTargetBtn = document.getElementById('setTargetBtn');
    const resetZoomBtn = document.getElementById('resetZoomBtn');
    const zoomSlider = document.getElementById('zoomSlider');
    const zoomValue = document.getElementById('zoomValue');
    const zoomLevelEl = document.getElementById('zoomLevel');
    const targetZoneEl = document.getElementById('targetZone');
    const detectionStatusEl = document.getElementById('detectionStatus');
    const riskLevelEl = document.getElementById('riskLevel');
    const modelStatusEl = document.getElementById('modelStatus');
    const confidenceTextEl = document.getElementById('confidenceText');
    const confidenceFillEl = document.getElementById('confidenceFill');
    const alarm = document.getElementById('alarm');

    // Simple lightweight ML model for basic object detection
    class SimpleMilkDetector {
      constructor() {
        this.isReady = false;
      }

      async load() {
        // Simulate model loading time
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        // Create a simple model using TensorFlow.js
        this.model = tf.sequential({
          layers: [
            tf.layers.conv2d({
              inputShape: [224, 224, 3],
              filters: 16,
              kernelSize: 3,
              activation: 'relu'
            }),
            tf.layers.maxPooling2d({poolSize: 2}),
            tf.layers.conv2d({filters: 32, kernelSize: 3, activation: 'relu'}),
            tf.layers.maxPooling2d({poolSize: 2}),
            tf.layers.flatten(),
            tf.layers.dense({units: 64, activation: 'relu'}),
            tf.layers.dense({units: 1, activation: 'sigmoid'})
          ]
        });

        this.isReady = true;
        return true;
      }

      async detect(videoElement) {
        if (!this.isReady) return { risk: 0, confidence: 0 };

        try {
          // Convert video frame to tensor
          const tensor = tf.browser.fromPixels(videoElement)
            .resizeNearestNeighbor([224, 224])
            .expandDims(0)
            .div(255.0);

          // Simulate detection with enhanced brightness and motion analysis
          const brightnessTensor = tensor.mean(3); // Convert to grayscale
          const avgBrightness = await brightnessTensor.mean().data();
          
          // Analyze texture patterns (foam detection)
          const edges = this.detectEdges(tensor);
          const edgeIntensity = await edges.mean().data();

          // Cleanup tensors
          tensor.dispose();
          brightnessTensor.dispose();
          edges.dispose();

          // Calculate risk based on brightness and texture
          const brightnessRisk = this.calculateBrightnessRisk(avgBrightness[0]);
          const textureRisk = this.calculateTextureRisk(edgeIntensity[0]);
          
          const combinedRisk = Math.min(1.0, brightnessRisk + textureRisk * 0.6);
          const confidence = Math.min(0.95, combinedRisk + 0.1);

          return {
            risk: combinedRisk,
            confidence: confidence,
            brightness: avgBrightness[0],
            texture: edgeIntensity[0]
          };

        } catch (error) {
          console.error('Detection error:', error);
          return { risk: 0, confidence: 0 };
        }
      }

      detectEdges(tensor) {
        // Simple edge detection using convolution
        const edgeKernel = tf.tensor4d([
          [[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]]
        ], [1, 3, 3, 1]);
        
        const grayTensor = tensor.mean(3, true); // Convert to grayscale
        const edges = tf.conv2d(grayTensor, edgeKernel, 1, 'same');
        
        edgeKernel.dispose();
        grayTensor.dispose();
        
        return tf.abs(edges);
      }

      calculateBrightnessRisk(brightness) {
        // Higher brightness = more foam = higher risk
        if (brightness > 0.8) return 0.9;
        if (brightness > 0.7) return 0.7;
        if (brightness > 0.6) return 0.4;
        return Math.max(0, (brightness - 0.3) * 2);
      }

      calculateTextureRisk(edgeIntensity) {
        // More edges/texture = more foam activity = higher risk
        if (edgeIntensity > 0.5) return 0.8;
        if (edgeIntensity > 0.3) return 0.5;
        if (edgeIntensity > 0.2) return 0.3;
        return edgeIntensity * 1.5;
      }
    }

    // Initialize the application
    async function init() {
      video = document.getElementById('video');
      model = new SimpleMilkDetector();
      
      try {
        await startCamera();
        updateStatus('loading', 'Loading ML model...');
        
        await model.load();
        modelStatusEl.textContent = 'Custom TensorFlow.js';
        modelLoaded = true;
        
        setupEventListeners();
        updateStatus('ready', 'Ready to monitor - Set target zone and start!');
        startBtn.disabled = false;
        
      } catch (error) {
        updateStatus('alert', 'Failed to initialize: ' + error.message);
        modelStatusEl.textContent = 'Failed to load';
        console.error('Initialization error:', error);
      }
    }

    async function startCamera() {
      if (!navigator.mediaDevices?.getUserMedia) {
        throw new Error('Camera API not supported on this device/browser.');
      }

      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          video: { 
            facingMode: "environment",
            width: { ideal: 640 },
            height: { ideal: 480 }
          } 
        });
        video.srcObject = stream;
        
        // Wait for video to be ready
        return new Promise((resolve) => {
          video.onloadedmetadata = () => {
            video.play();
            resolve();
          };
        });
      } catch (err) {
        throw new Error('Camera access required: ' + err.message);
      }
    }

    function setupEventListeners() {
      // Zoom controls - Fixed implementation
      zoomSlider.addEventListener('input', (e) => {
        zoomLevel = parseFloat(e.target.value);
        updateZoom();
      });

      resetZoomBtn.addEventListener('click', () => {
        zoomLevel = 1.0;
        zoomSlider.value = 1.0;
        updateZoom();
      });

      // Target zone setting
      setTargetBtn.addEventListener('click', () => {
        isSettingTarget = !isSettingTarget;
        setTargetBtn.textContent = isSettingTarget ? 'Cancel Target' : 'Set Target Zone';
        setTargetBtn.style.background = isSettingTarget ? '#dc3545' : '#007bff';
        
        if (isSettingTarget) {
          video.style.cursor = 'crosshair';
          updateStatus('ready', 'Click and drag to set target zone');
        } else {
          video.style.cursor = 'default';
          updateStatus('ready', 'Ready to monitor');
        }
      });

      // Target zone selection - Fixed for mobile
      let startX, startY, isDrawing = false;
      
      const getCoordinates = (e) => {
        const rect = video.getBoundingClientRect();
        const clientX = e.clientX || (e.touches && e.touches[0].clientX);
        const clientY = e.clientY || (e.touches && e.touches[0].clientY);
        return {
          x: clientX - rect.left,
          y: clientY - rect.top
        };
      };

      const startDrawing = (e) => {
        if (!isSettingTarget) return;
        e.preventDefault();
        
        const coords = getCoordinates(e);
        startX = coords.x;
        startY = coords.y;
        isDrawing = true;
        
        targetZoneEl.style.left = startX + 'px';
        targetZoneEl.style.top = startY + 'px';
        targetZoneEl.style.width = '0px';
        targetZoneEl.style.height = '0px';
        targetZoneEl.style.display = 'block';
      };

      const updateDrawing = (e) => {
        if (!isSettingTarget || !isDrawing) return;
        e.preventDefault();
        
        const coords = getCoordinates(e);
        const width = Math.abs(coords.x - startX);
        const height = Math.abs(coords.y - startY);
        const left = Math.min(startX, coords.x);
        const top = Math.min(startY, coords.y);
        
        targetZoneEl.style.left = left + 'px';
        targetZoneEl.style.top = top + 'px';
        targetZoneEl.style.width = width + 'px';
        targetZoneEl.style.height = height + 'px';
      };

      const endDrawing = (e) => {
        if (!isSettingTarget || !isDrawing) return;
        e.preventDefault();
        
        const coords = getCoordinates(e);
        const rect = video.getBoundingClientRect();
        
        // Store target zone coordinates (normalized to video dimensions)
        targetZone = {
          x: Math.min(startX, coords.x) / rect.width,
          y: Math.min(startY, coords.y) / rect.height,
          width: Math.abs(coords.x - startX) / rect.width,
          height: Math.abs(coords.y - startY) / rect.height
        };
        
        isDrawing = false;
        isSettingTarget = false;
        setTargetBtn.textContent = 'Set Target Zone';
        setTargetBtn.style.background = '#007bff';
        video.style.cursor = 'default';
        
        updateStatus('ready', 'Target zone set! Ready to monitor');
      };

      // Mouse events
      video.addEventListener('mousedown', startDrawing);
      video.addEventListener('mousemove', updateDrawing);
      video.addEventListener('mouseup', endDrawing);

      // Touch events for mobile
      video.addEventListener('touchstart', startDrawing);
      video.addEventListener('touchmove', updateDrawing);
      video.addEventListener('touchend', endDrawing);

      // Start monitoring
      startBtn.addEventListener('click', () => {
        if (!monitoring) {
          monitoring = true;
          startBtn.textContent = 'Stop Monitoring';
          startBtn.style.background = '#dc3545';
          updateStatus('monitoring', 'Monitoring for milk overflow...');
          monitorFrame();
        } else {
          monitoring = false;
          startBtn.textContent = 'Start Monitoring';
          startBtn.style.background = '#007bff';
          updateStatus('ready', 'Monitoring stopped');
          updateDetectionInfo('Standby', 'Low', 0);
        }
      });
    }

    function updateZoom() {
      // Apply zoom transform to video
      video.style.transform = `scale(${zoomLevel})`;
      zoomValue.textContent = `${zoomLevel.toFixed(1)}x`;
      zoomLevelEl.textContent = `Zoom: ${zoomLevel.toFixed(1)}x`;
      
      console.log('Zoom updated to:', zoomLevel); // Debug log
    }

    function updateStatus(type, message) {
      statusEl.className = `status ${type}`;
      statusEl.textContent = message;
    }

    function updateDetectionInfo(status, risk, confidence) {
      detectionStatusEl.textContent = status;
      riskLevelEl.textContent = risk;
      confidenceTextEl.textContent = `${Math.round(confidence * 100)}%`;
      confidenceFillEl.style.width = `${confidence * 100}%`;
      
      // Update risk level color
      const riskEl = document.getElementById('riskLevel');
      if (risk === 'High') {
        riskEl.style.color = '#dc3545';
        riskEl.style.fontWeight = 'bold';
      } else if (risk === 'Medium') {
        riskEl.style.color = '#ffc107';
        riskEl.style.fontWeight = 'bold';
      } else {
        riskEl.style.color = '#28a745';
        riskEl.style.fontWeight = 'normal';
      }
    }

    async function monitorFrame() {
      if (!monitoring || !modelLoaded) return;

      try {
        // Run ML detection
        const result = await model.detect(video);
        
        let status = 'Monitoring';
        let risk = 'Low';
        let finalRisk = result.risk;

        // Enhance risk if target zone is set and we're focusing on it
        if (targetZone) {
          finalRisk *= 1.2; // Boost sensitivity in target zone
        }

        // Determine risk level and status
        if (finalRisk > 0.75) {
          status = 'HIGH RISK DETECTED!';
          risk = 'High';
          updateStatus('alert', 'ðŸš¨ MILK OVERFLOW IMMINENT!');
          triggerAlarm();
        } else if (finalRisk > 0.5) {
          status = 'Elevated Risk';
          risk = 'Medium';
          updateStatus('monitoring', 'âš ï¸ Monitoring - Elevated risk detected');
        } else if (finalRisk > 0.2) {
          status = 'Activity Detected';
          risk = 'Low';
          updateStatus('monitoring', 'Monitoring - Some activity detected');
        } else {
          status = 'Monitoring';
          risk = 'Low';
          updateStatus('monitoring', 'Monitoring - All clear');
        }

        updateDetectionInfo(status, risk, result.confidence || finalRisk);

      } catch (error) {
        console.error('Detection error:', error);
        updateDetectionInfo('Error', 'Unknown', 0);
      }

      // Continue monitoring
      if (monitoring) {
        setTimeout(() => requestAnimationFrame(monitorFrame), 200); // Check every 200ms
      }
    }

    function triggerAlarm() {
      // Play alarm sound
      alarm.play().catch(e => console.log('Audio play failed:', e));
      
      // Visual alert
      document.body.style.backgroundColor = '#ffebee';
      setTimeout(() => {
        document.body.style.backgroundColor = '#f5f5f5';
      }, 1000);
      
      // Vibration if supported
      if ('vibrate' in navigator) {
        navigator.vibrate([200, 100, 200, 100, 200]);
      }
      
      // Stop monitoring after alert
      setTimeout(() => {
        if (monitoring) {
          monitoring = false;
          startBtn.textContent = 'Start Monitoring';
          startBtn.style.background = '#007bff';
          updateStatus('alert', 'Alert triggered! Monitoring stopped.');
        }
      }, 3000);
    }

    // Initialize the application when page loads
    window.addEventListener('load', init);
  </script>
</body>
</html>